# Enhanced Telco Dataset Generator with Text Data


# Telco Customer Churn ‚Äì Synthetic Dataset with Data Drift

 [![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)

 [![Python 3.9+](https://img.shields.io/badge/python-3.9%2B-blue)](https://www.python.org/downloads/)


## Synthetic dataset for working through the full MLOps cycle:

- training churn classification models

- monitoring data drift / concept drift

- automated retraining

- shadow datasets, A/B testing models, etc.

 

 **Does not contain any real customer records** ‚Äì completely generated programmatically.

 

### Source of inspiration

 The structure and statistical distributions are based on a public dataset:

 **Telco Customer Churn**

 https://www.kaggle.com/datasets/blastchar/telco-customer-churn

 Original license: CC BY-NC-SA 4.0

 

## This repository does not contain or distribute the original dataset.

 

### Synthetic Data Features

- 100,000+ records

- Period: 2023-01-01 ‚Üí 2024-12-31

- Gradual conceptual drift (Fiber optic growth, Electronic check decline, churn decline, etc.)

- `RecordDate` column for time analysis

- Realistic dependencies between features (like in the real world)

 

## How to generate a dataset


## 1. Clone the repository

```sh
 git clone https://github.com/<your repo>/telco-churn-mlops-synthetic.git
```
```sh
 cd telco-churn-mlops-synthetic
```
 

## 2. Create a virtual environment and install dependencies

```sh
 python -m venv venv
```
```sh
 source venv/bin/activate # Windows: venv\\Scripts\\activate
```
```sh
 pip install -r requirements.txt
```
 

## 3. Generate a dataset


## Standatd generation
```sh
python generate_dataset.py
```
## Custom generation
```sh
python generate_dataset.py --samples 100000 --output-dir my_data/
```
## Custom generation with date

```sh
python generate_dataset.py --samples 50000 --start-date 2022-01-01 --end-date 2024-12-31
```

## Enhanced Custom generation

# –ó–≤–∏—á–∞–π–Ω–∏–π –∑–∞–ø—É—Å–∫ (–≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î config.yaml)
```sh
python src/generate_dataset_ext.py
```
# –ü–µ—Ä–µ–≤–∏–∑–Ω–∞—á–∏—Ç–∏ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∫–ª—ñ—î–Ω—Ç—ñ–≤
```sh
python src/generate_dataset_ext.py --override-samples 20000
```
# –í–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ —ñ–Ω—à–∏–π –∫–æ–Ω—Ñ—ñ–≥
```sh
python src/generate_dataset_ext.py --config config/my_experiment.yaml
```
# Full extended
```sh
python src/generate_dataset_ext.py --samples 20000 --conv-samples 3000
```

## üìä What will you get?

data/
‚îú‚îÄ‚îÄ telco_customers.csv           # 50,000 clients with drift
‚îú‚îÄ‚îÄ support_conversations.csv     # ~7,500 dialogs
‚îú‚îÄ‚îÄ knowledge_base.csv            # 8 documents
‚îî‚îÄ‚îÄ knowledge_base.json           # The same in json JSON
=======
# Telco Customer Churn ‚Äì Synthetic Dataset with Data Drift

 [![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
[![Python 3.9+](https://img.shields.io/badge/python-3.9%2B-blue)](https://www.python.org/downloads/)

 
 ### Synthetic dataset for working through the full MLOps cycle:

 - training churn classification models

 - monitoring data drift / concept drift

 - automated retraining

 - shadow datasets, A/B testing models, etc.

 

 **Does not contain any real customer records** ‚Äì completely generated programmatically.

 

 ### Source of inspiration

 The structure and statistical distributions are based on a public dataset:

 **Telco Customer Churn**

 https://www.kaggle.com/datasets/blastchar/telco-customer-churn

 Original license: CC BY-NC-SA 4.0

 

 This repository does not contain or distribute the original dataset.

 

 ### Synthetic Data Features

 - 100,000+ records

 - Period: 2023-01-01 ‚Üí 2024-12-31

 - Gradual conceptual drift (Fiber optic growth, Electronic check decline, churn decline, etc.)

 - `RecordDate` column for time analysis

 - Realistic dependencies between features (like in the real world)


–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó —â–æ–¥–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –∑ make

make help                # –ø–æ–¥–∏–≤–∏—Ç–∏—Å—è –≤—Å—ñ –¥–æ—Å—Ç—É–ø–Ω—ñ –∫–æ–º–∞–Ω–¥–∏
make install             # –ø–µ—Ä—à–∏–π —Ä–∞–∑
make install-dev         # —è–∫—â–æ —Ö–æ—á–µ—Ç–µ ruff, black, jupyter
make generate-ext        # –æ—Å–Ω–æ–≤–Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—è
make explore             # –≤—ñ–¥–∫—Ä–∏—Ç–∏ Jupyter
make lint                # –ø–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ —Å—Ç–∏–ª—å
make format              # –≤–∏–ø—Ä–∞–≤–∏—Ç–∏ —Å—Ç–∏–ª—å
make clean-data          # –æ—á–∏—Å—Ç–∏—Ç–∏ —Ç—ñ–ª—å–∫–∏ –¥–∞–Ω—ñ


# 1. –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –¥–∞–Ω–∏—Ö (—è–∫ —Ä–∞–Ω—ñ—à–µ)
make docker-up
# –∞–±–æ
docker compose up -d generator

# 2. –ó–∞–ø—É—Å–∫ Jupyter
make jupyter-up

# 3. –î–∏–≤–∏–º–æ—Å—è –ª–æ–≥–∏ ‚Üí —Ç–∞–º –±—É–¥–µ –ø–æ—Å–∏–ª–∞–Ω–Ω—è —Ç–∞ token
make jupyter-logs

# –ü—Ä–∏–∫–ª–∞–¥ –≤–∏–≤–æ–¥—É –≤ –ª–æ–≥–∞—Ö:
#     http://127.0.0.1:8888/lab?token=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# 4. –ó—É–ø–∏–Ω–∏—Ç–∏ Jupyter
make jupyter-down
–Ø–∫—â–æ —Ö–æ—á–µ—Ç–µ –∑–∞–ø—É—Å–∫–∞—Ç–∏ Jupyter –±–µ–∑ docker-compose (–æ–¥–Ω–æ—Ä–∞–∑–æ–≤–æ)
–î–æ–¥–∞–π—Ç–µ –≤ Makefile —â–µ –æ–¥–Ω—É —Ü—ñ–ª—å (–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞):
makefilejupyter-standalone: ## –ó–∞–ø—É—Å—Ç–∏—Ç–∏ Jupyter –æ–¥–Ω–∏–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–º –±–µ–∑ compose
	docker run -d \
		--name temp-jupyter \
		-p 8888:8888 \
		-v $(PWD)/notebooks:/home/jovyan/work \
		-v $(PWD)/data:/home/jovyan/data:ro \
		-e JUPYTER_ENABLE_LAB=yes \
		-e JUPYTER_TOKEN=secret123 \
		quay.io/jupyter/scipy-notebook:latest

jupyter-standalone-stop: ## –ó—É–ø–∏–Ω–∏—Ç–∏ —Ç–∞ –≤–∏–¥–∞–ª–∏—Ç–∏ standalone Jupyter
	docker stop temp-jupyter && docker rm temp-jupyter 
